{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Research dataset\n",
    "stairtのデータセットとオリジナルのデータセットを合わしたいのでそのための調査スクリプト"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import pickle\n",
    "import json\n",
    "from pycocotools.coco import COCO\n",
    "import numpy as np\n",
    "import skimage.io as io\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "pylab.rcParams['figure.figsize'] = (8.0, 10.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=2.30s)\n",
      "creating index...\n",
      "index created!\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "TRAIN_IMAGES_DIRECTORY = \"/home/nakachi/data/stair/train2014\"\n",
    "TRAIN_ANNOTATIONS_PATH = \"/home/nakachi/data/stair/stair_captions_v1.2_train_tokenized.json\"\n",
    "\n",
    "coco = COCO(TRAIN_ANNOTATIONS_PATH)\n",
    "\n",
    "img_ids = 384553\n",
    "annotation_ids = coco.getAnnIds(imgIds=img_ids)\n",
    "print(annotation_ids)\n",
    "annotations = coco.loadAnns(annotation_ids)\n",
    "\n",
    "for i in range(len(annotations)):\n",
    "    entity_id = annotations[i][\"category_id\"]\n",
    "    entity = coco.loadCats(entity_id)[0][\"name\"]\n",
    "    print('hi')\n",
    "    print(\"{}: {}\".format(i, entity))\n",
    "\n",
    "\n",
    "# image_meta = coco.loadImgs(annotations[i][\"image_id\"])[0]\n",
    "# image_path = os.path.join(TRAIN_IMAGES_DIRECTORY, image_meta[\"file_name\"])\n",
    "\n",
    "# I = io.imread(image_path)\n",
    "# plt.imshow(I)\n",
    "# coco.showAnns(annotations)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "stairtとオリジナルデータセットのアノテーションの差分を調べる。\n",
    "差分があった場合、Stairに合わせたデータセットをつくる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.68s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=4.88s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "STAIR_VAL_ANNOTATIONS_PATH = \"/home/nakachi/data/stair/stair_captions_v1.2_val_tokenized.json\"\n",
    "INSTA_VAL_ANNOTATIONS_PATH = \"/home/nakachi/data/coco2014/annotations/instances_val2014.json\"\n",
    "stair_val_coco = COCO(STAIR_VAL_ANNOTATIONS_PATH)\n",
    "insta_val_coco = COCO(INSTA_VAL_ANNOTATIONS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insta_val_coco.cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stair val img length: 40504\n",
      "insta val img length: 40504\n"
     ]
    }
   ],
   "source": [
    "print('stair val img length:', len(stair_val_coco.imgs))\n",
    "print('insta val img length:', len(insta_val_coco.imgs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stair val anns length: 202520\n",
      "insta val anns length: 291875\n"
     ]
    }
   ],
   "source": [
    "print('stair val anns length:', len(stair_val_coco.anns))\n",
    "print('insta val anns length:', len(insta_val_coco.anns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上記を見て分かるように、imgの数は合っているが、\n",
    "アノテーションの数が違う。\n",
    "\n",
    "stairは１画像に対して、5captionあるから合っている。\n",
    "\n",
    "instaがわからんので調べる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_anns = dict()\n",
    "for value in insta_val_coco.anns.values():\n",
    "    image_id = value['image_id']\n",
    "    pre_ann_num = images_anns.get(image_id, 0)\n",
    "    images_anns[image_id] = pre_ann_num + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_anns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "annotionがない画像もあるやんけ〜〜〜〜\n",
    "\n",
    "しかも1画像あたりに対して、めっちゃannotationがあるのもある...\n",
    "\n",
    "ないやつはシカトでOKだけど、あるやつどうしようかな\n",
    "\n",
    "いや待て、これはinstaだからか！？\n",
    "ここはカテゴリだけ、使えればよくて本来のcaptionの方を調べる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stair_val_coco.anns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "captionの概観を掴む"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.72s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.33s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "STAIR_VAL_ANNOTATIONS_PATH = \"/home/nakachi/data/stair/stair_captions_v1.2_val_tokenized.json\"\n",
    "CAPTION_VAL_ANNOTATIONS_PATH = \"/home/nakachi/data/coco2014/annotations/captions_val2014.json\"\n",
    "stair_val_coco = COCO(STAIR_VAL_ANNOTATIONS_PATH)\n",
    "caption_val_coco = COCO(CAPTION_VAL_ANNOTATIONS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caption_val_coco.cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stair val anns length: 202520\n",
      "caption val anns length: 202654\n"
     ]
    }
   ],
   "source": [
    "print('stair val anns length:', len(stair_val_coco.anns))\n",
    "print('caption val anns length:', len(caption_val_coco.anns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1画像あたりのannotation数\n",
    "images_anns = dict()\n",
    "for value in caption_val_coco.anns.values():\n",
    "    image_id = value['image_id']\n",
    "    pre_ann_num = images_anns.get(image_id, 0)\n",
    "    images_anns[image_id] = pre_ann_num + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最低5captionは必要なのでそれがあるか確認\n",
    "for k, v in images_anns.items():\n",
    "    if v < 5:\n",
    "        print(k, v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "カテゴリ別でデータセットを分けたい。\n",
    "そのために以下のような辞書を作る\n",
    "```\n",
    "cat_img_dic = {id: {'name': 'person', 'image_ids: [...]},\n",
    "               id: {'name': 'person', 'image_ids: [...]},\n",
    "               ...\n",
    "              }\n",
    "\n",
    "```\n",
    "また、最初は1 imageにつき1 categoryにしようと思ったが、\n",
    "別にそうしないことにした。（たくさんあった方がいい）\n",
    "\n",
    "ただし、image_idsはユニークをとる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=5.48s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "INSTA_VAL_ANNOTATIONS_PATH = \"/home/nakachi/data/coco2014/annotations/instances_val2014.json\"\n",
    "insta_val_coco = COCO(INSTA_VAL_ANNOTATIONS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=11.33s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "INSTA_TRAIN_ANNOTATIONS_PATH = \"/home/nakachi/data/coco2014/annotations/instances_train2014.json\"\n",
    "insta_train_coco = COCO(INSTA_TRAIN_ANNOTATIONS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(insta_train_coco.cats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_img_dic = dict()\n",
    "# 最初にカテゴリーのidとname, image_idsの空配列を最初に作る\n",
    "for cat_value in insta_val_coco.cats.values():\n",
    "    cat_img_dic[cat_value['id']] = {'name': cat_value['name'], 'image_ids': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 次に各カテゴリーに対応するimage_idを追加していく\n",
    "# NOTE: ひとつの画像に足して複数のカテゴリーがある場合がある\n",
    "for ann_dic_val in insta_val_coco.anns.values():\n",
    "    image_id = ann_dic_val['image_id']\n",
    "    category_id = ann_dic_val['category_id']\n",
    "    cat_img_dic[category_id]['image_ids'].append(image_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "減る前の確認. personの数は=  88153\n",
      "減ったか確認. personの数は=  21634\n"
     ]
    }
   ],
   "source": [
    "# image_idsをユニークにする\n",
    "print('減る前の確認. personの数は= ', len(cat_img_dic[1]['image_ids']))\n",
    "for k, v in cat_img_dic.items():\n",
    "    cat_img_dic[k]['image_ids'] = list(set(cat_img_dic[k]['image_ids']))\n",
    "\n",
    "print('減ったか確認. personの数は= ', len(cat_img_dic[1]['image_ids']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# できた！！！ので各カテゴリーにどれぐらいのimageがあるか確認\n",
    "for cat_val in cat_img_dic.values():\n",
    "    print('カテゴリ名 = ', cat_val['name'])\n",
    "    print('imageの数 = ', len(cat_val['image_ids']))\n",
    "    print('--------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "実際に分けていく。valとtrainで分ける。\n",
    "1. cat_img_dicを作成する\n",
    "1. caption.jsonを読み込んで、対応するimageの名前とcaptionに対応した辞書を作る\n",
    "1. annotationをappendする\n",
    "\n",
    "```\n",
    "category_split\n",
    "├── person_en\n",
    "│   ├── train_filenames.pickle\n",
    "│   ├── val_filenames.pickle\n",
    "│   └── text\n",
    "│       └── COCO_VAL_0000.txt\n",
    "└── person_ja\n",
    "    ├── train_filenames.pickle\n",
    "    ├── val_filenames.pickle\n",
    "    └── text\n",
    "        └── COCO_VAL_0000.txt\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "cat_images_dicを作成する関数\n",
    "cat_images_dic = {id: {'name': 'person', 'image_ids: [...]},\n",
    "                  id: {'name': 'person', 'image_ids: [...]},\n",
    "                  ...\n",
    "                  }\n",
    "'''\n",
    "def make_cat_images_dic(insta_path):\n",
    "    insta_coco = COCO(insta_path)\n",
    "\n",
    "\n",
    "    cat_images_dic = dict()\n",
    "    # 最初にカテゴリーのidとname, image_idsの空配列を最初に作る\n",
    "    for cat_value in insta_coco.cats.values():\n",
    "        cat_images_dic[cat_value['id']] = {'name': cat_value['name'], 'image_ids': []}\n",
    "\n",
    "\n",
    "    # 次に各カテゴリーに対応するimage_idを追加していく\n",
    "    # NOTE: ひとつの画像に足して複数のカテゴリーがある場合がある\n",
    "    for ann_dic_val in insta_coco.anns.values():\n",
    "        image_id = ann_dic_val['image_id']\n",
    "        category_id = ann_dic_val['category_id']\n",
    "        cat_images_dic[category_id]['image_ids'].append(image_id)\n",
    "\n",
    "    # image_idsをユニークにする\n",
    "    for k, v in cat_images_dic.items():\n",
    "        cat_images_dic[k]['image_ids'] = list(set(cat_images_dic[k]['image_ids']))\n",
    "    \n",
    "    return cat_images_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "imageとcaptionが対応したdictを作成する関数\n",
    "image_captions_dic = {id: {'name': file_name, 'captions': [...]},\n",
    "                      id: {'name': file_name, 'captions': [...]},\n",
    "                      ...\n",
    "                      }\n",
    "'''\n",
    "\n",
    "def make_image_captions_dic(caption_path):\n",
    "    # json読み込み\n",
    "    with open(caption_path, encoding='utf-8') as f:\n",
    "        json_data = json.load(f)\n",
    "    \n",
    "    image_captions = {}\n",
    "    for i in range(len(json_data[\"images\"])):\n",
    "        file_name = json_data[\"images\"][i][\"file_name\"]\n",
    "        image_id = json_data[\"images\"][i][\"id\"]\n",
    "        image_captions[image_id] = {'name': file_name.replace('.jpg', ''), 'captions': []}\n",
    "    \n",
    "    for annotation in json_data['annotations']:\n",
    "        image_id = annotation['image_id']\n",
    "        if 'tokenized_caption' in annotation:\n",
    "            image_captions[image_id]['captions'].append(annotation['tokenized_caption'])\n",
    "        elif 'caption' in annotation:\n",
    "            image_captions[image_id]['captions'].append(annotation['caption'])\n",
    "    \n",
    "    return image_captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_text_data(image_ids, image_captions_dic, text_dir_path):\n",
    "    for image_id in image_ids:\n",
    "        w_captions = \"\\n\".join(image_captions_dic[image_id]['captions'])\n",
    "        save_text_path = os.path.join(text_dir_path, image_captions_dic[image_id]['name'] + '.txt')\n",
    "        with open(save_text_path, 'w', encoding='utf-8') as f:\n",
    "            f.write(w_captions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_filenames_pickle(image_ids, image_captions_dic, data_dir_path, train_or_val):\n",
    "    filename_list = []\n",
    "    for image_id in image_ids:\n",
    "        filename_list.append(image_captions_dic[image_id]['name'])\n",
    "    \n",
    "    save_filename_path = os.path.join(data_dir_path, train_or_val + '_filenames.pickle')\n",
    "    with open(save_filename_path, 'wb') as f:\n",
    "        pickle.dump(filename_list,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPLIT_DIR_PATH = '/home/nakachi/data/category_split'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=7.36s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "val_insta_path = '/home/nakachi/data/coco2014/annotations/instances_val2014.json'\n",
    "val_en_caption_path = '/home/nakachi/data/coco2014/annotations/captions_val2014.json'\n",
    "val_ja_caption_path = '/data/Users/nakachi/stair/stair_captions_v1.2_val_tokenized.json'\n",
    "\n",
    "val_cat_images_dic = make_cat_images_dic(val_insta_path)\n",
    "val_en_image_captions_dic = make_image_captions_dic(val_en_caption_path)\n",
    "val_ja_image_captions_dic = make_image_captions_dic(val_ja_caption_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cat_images in val_cat_images_dic.values():\n",
    "    # en: オリジナル\n",
    "    EN_DATA_DIR = os.path.join(SPLIT_DIR_PATH, cat_images['name'] + '_en')\n",
    "    EN_TEXT_DIR = os.path.join(EN_DATA_DIR, 'text')\n",
    "    os.makedirs(EN_TEXT_DIR, exist_ok=True)\n",
    "    make_text_data(cat_images['image_ids'], val_en_image_captions_dic, EN_TEXT_DIR)\n",
    "    make_filenames_pickle(cat_images['image_ids'], val_en_image_captions_dic, EN_DATA_DIR, 'val')\n",
    "    \n",
    "    \n",
    "    # ja: stair\n",
    "    JA_DATA_DIR = os.path.join(SPLIT_DIR_PATH, cat_images['name'] + '_ja')\n",
    "    JA_TEXT_DIR = os.path.join(JA_DATA_DIR, 'text')\n",
    "    os.makedirs(JA_TEXT_DIR, exist_ok=True)\n",
    "    make_text_data(cat_images['image_ids'], val_ja_image_captions_dic, JA_TEXT_DIR)\n",
    "    make_filenames_pickle(cat_images['image_ids'], val_ja_image_captions_dic, JA_DATA_DIR, 'val')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=10.85s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "train_insta_path = '/home/nakachi/data/coco2014/annotations/instances_train2014.json'\n",
    "train_en_caption_path = '/home/nakachi/data/coco2014/annotations/captions_train2014.json'\n",
    "train_ja_caption_path = '/data/Users/nakachi/stair/stair_captions_v1.2_train_tokenized.json'\n",
    "\n",
    "train_cat_images_dic = make_cat_images_dic(train_insta_path)\n",
    "train_en_image_captions_dic = make_image_captions_dic(train_en_caption_path)\n",
    "train_ja_image_captions_dic = make_image_captions_dic(train_ja_caption_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cat_images in train_cat_images_dic.values():\n",
    "    # en: オリジナル\n",
    "    EN_DATA_DIR = os.path.join(SPLIT_DIR_PATH, cat_images['name'] + '_en')\n",
    "    EN_TEXT_DIR = os.path.join(EN_DATA_DIR, 'text')\n",
    "    os.makedirs(EN_TEXT_DIR, exist_ok=True)\n",
    "    make_text_data(cat_images['image_ids'], train_en_image_captions_dic, EN_TEXT_DIR)\n",
    "    make_filenames_pickle(cat_images['image_ids'], train_en_image_captions_dic, EN_DATA_DIR, 'train')\n",
    "    \n",
    "    \n",
    "    # ja: stair\n",
    "    JA_DATA_DIR = os.path.join(SPLIT_DIR_PATH, cat_images['name'] + '_ja')\n",
    "    JA_TEXT_DIR = os.path.join(JA_DATA_DIR, 'text')\n",
    "    os.makedirs(JA_TEXT_DIR, exist_ok=True)\n",
    "    make_text_data(cat_images['image_ids'], train_ja_image_captions_dic, JA_TEXT_DIR)\n",
    "    make_filenames_pickle(cat_images['image_ids'], train_ja_image_captions_dic, JA_DATA_DIR, 'train')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "できた！！！\n",
    "次はデータの統計を掴む"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandasに適用するためにそれぞれのlistを作る\n",
    "train_list = []\n",
    "val_list = []\n",
    "\n",
    "for train_value in train_cat_images_dic.values():\n",
    "    append_list = [train_value['name'], len(train_value['image_ids'])]\n",
    "    train_list.append(append_list)\n",
    "    \n",
    "for val_value in val_cat_images_dic.values():\n",
    "    append_list = [val_value['name'], len(val_value['image_ids'])]\n",
    "    val_list.append(append_list)\n",
    "\n",
    "train_df = pd.DataFrame(train_list)\n",
    "val_df = pd.DataFrame(val_list)\n",
    "train_df.columns = ['name', 'number of image']\n",
    "val_df.columns = ['name', 'number of image']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             name  number of image\n",
      "0          person            45174\n",
      "56          chair             8950\n",
      "2             car             8606\n",
      "60   dining table             8378\n",
      "41            cup             6518\n",
      "..            ...              ...\n",
      "76       scissors              673\n",
      "21           bear              668\n",
      "12  parking meter              481\n",
      "70        toaster              151\n",
      "78     hair drier              128\n",
      "\n",
      "[80 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "train_df_s = train_df.sort_values('number of image', ascending=False)\n",
    "print(train_df_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             name  number of image\n",
      "0          person            21634\n",
      "56          chair             4404\n",
      "2             car             4180\n",
      "60   dining table             3960\n",
      "41            cup             3061\n",
      "..            ...              ...\n",
      "21           bear              341\n",
      "76       scissors              302\n",
      "12  parking meter              261\n",
      "70        toaster               74\n",
      "78     hair drier               70\n",
      "\n",
      "[80 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "val_df_s = val_df.sort_values('number of image', ascending=False)\n",
    "print(val_df_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
