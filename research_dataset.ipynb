{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Research dataset\n",
    "stairtのデータセットとオリジナルのデータセットを合わしたいのでそのための調査スクリプト"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import pickle\n",
    "import json\n",
    "from pycocotools.coco import COCO\n",
    "import numpy as np\n",
    "import skimage.io as io\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "pylab.rcParams['figure.figsize'] = (8.0, 10.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=2.01s)\n",
      "creating index...\n",
      "index created!\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "TRAIN_IMAGES_DIRECTORY = \"/home/nakachi/data/stair/train2014\"\n",
    "TRAIN_ANNOTATIONS_PATH = \"/home/nakachi/data/stair/stair_captions_v1.2_train_tokenized.json\"\n",
    "\n",
    "coco = COCO(TRAIN_ANNOTATIONS_PATH)\n",
    "\n",
    "img_ids = 384553\n",
    "annotation_ids = coco.getAnnIds(imgIds=img_ids)\n",
    "print(annotation_ids)\n",
    "annotations = coco.loadAnns(annotation_ids)\n",
    "\n",
    "for i in range(len(annotations)):\n",
    "    entity_id = annotations[i][\"category_id\"]\n",
    "    entity = coco.loadCats(entity_id)[0][\"name\"]\n",
    "    print('hi')\n",
    "    print(\"{}: {}\".format(i, entity))\n",
    "\n",
    "\n",
    "# image_meta = coco.loadImgs(annotations[i][\"image_id\"])[0]\n",
    "# image_path = os.path.join(TRAIN_IMAGES_DIRECTORY, image_meta[\"file_name\"])\n",
    "\n",
    "# I = io.imread(image_path)\n",
    "# plt.imshow(I)\n",
    "# coco.showAnns(annotations)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "stairtとオリジナルデータセットのアノテーションの差分を調べる。\n",
    "差分があった場合、Stairに合わせたデータセットをつくる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.85s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=6.44s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "STAIR_VAL_ANNOTATIONS_PATH = \"/home/nakachi/data/stair/stair_captions_v1.2_val_tokenized.json\"\n",
    "INSTA_VAL_ANNOTATIONS_PATH = \"/home/nakachi/data/coco2014/annotations/instances_val2014.json\"\n",
    "stair_val_coco = COCO(STAIR_VAL_ANNOTATIONS_PATH)\n",
    "insta_val_coco = COCO(INSTA_VAL_ANNOTATIONS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insta_val_coco.cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stair val img length: 40504\n",
      "insta val img length: 40504\n"
     ]
    }
   ],
   "source": [
    "print('stair val img length:', len(stair_val_coco.imgs))\n",
    "print('insta val img length:', len(insta_val_coco.imgs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stair val anns length: 202520\n",
      "insta val anns length: 291875\n"
     ]
    }
   ],
   "source": [
    "print('stair val anns length:', len(stair_val_coco.anns))\n",
    "print('insta val anns length:', len(insta_val_coco.anns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上記を見て分かるように、imgの数は合っているが、\n",
    "アノテーションの数が違う。\n",
    "\n",
    "stairは１画像に対して、5captionあるから合っている。\n",
    "\n",
    "instaがわからんので調べる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_anns = dict()\n",
    "for value in insta_val_coco.anns.values():\n",
    "    image_id = value['image_id']\n",
    "    pre_ann_num = images_anns.get(image_id, 0)\n",
    "    images_anns[image_id] = pre_ann_num + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_anns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "annotionがない画像もあるやんけ〜〜〜〜\n",
    "\n",
    "しかも1画像あたりに対して、めっちゃannotationがあるのもある...\n",
    "\n",
    "ないやつはシカトでOKだけど、あるやつどうしようかな\n",
    "\n",
    "いや待て、これはinstaだからか！？\n",
    "ここはカテゴリだけ、使えればよくて本来のcaptionの方を調べる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stair_val_coco.anns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "captionの概観を掴む"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.84s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.33s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "STAIR_VAL_ANNOTATIONS_PATH = \"/home/nakachi/data/stair/stair_captions_v1.2_val_tokenized.json\"\n",
    "CAPTION_VAL_ANNOTATIONS_PATH = \"/home/nakachi/data/coco2014/annotations/captions_val2014.json\"\n",
    "stair_val_coco = COCO(STAIR_VAL_ANNOTATIONS_PATH)\n",
    "caption_val_coco = COCO(CAPTION_VAL_ANNOTATIONS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "caption_val_coco.anns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stair val anns length: 202520\n",
      "caption val anns length: 202654\n"
     ]
    }
   ],
   "source": [
    "print('stair val anns length:', len(stair_val_coco.anns))\n",
    "print('caption val anns length:', len(caption_val_coco.anns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1画像あたりのannotation数\n",
    "images_anns = dict()\n",
    "for value in caption_val_coco.anns.values():\n",
    "    image_id = value['image_id']\n",
    "    pre_ann_num = images_anns.get(image_id, 0)\n",
    "    images_anns[image_id] = pre_ann_num + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最低5captionは必要なのでそれがあるか確認\n",
    "for k, v in images_anns.items():\n",
    "    if v < 5:\n",
    "        print(k, v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "カテゴリ別でデータセットを分けたい。\n",
    "そのために以下のような辞書を作る\n",
    "```\n",
    "cat_img_dic = {id: {'name': 'person', 'image_ids: [...]},\n",
    "               id: {'name': 'person', 'image_ids: [...]},\n",
    "               ...\n",
    "              }\n",
    "\n",
    "```\n",
    "また、最初は1 imageにつき1 categoryにしようと思ったが、\n",
    "別にそうしないことにした。（たくさんあった方がいい）\n",
    "\n",
    "ただし、image_idsはユニークをとる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=6.84s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "INSTA_VAL_ANNOTATIONS_PATH = \"/home/nakachi/data/coco2014/annotations/instances_val2014.json\"\n",
    "insta_val_coco = COCO(INSTA_VAL_ANNOTATIONS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=11.38s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "INSTA_TRAIN_ANNOTATIONS_PATH = \"/home/nakachi/data/coco2014/annotations/instances_train2014.json\"\n",
    "insta_train_coco = COCO(INSTA_TRAIN_ANNOTATIONS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(insta_train_coco.cats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_img_dic = dict()\n",
    "# 最初にカテゴリーのidとname, image_idsの空配列を最初に作る\n",
    "for cat_value in insta_val_coco.cats.values():\n",
    "    cat_img_dic[cat_value['id']] = {'name': cat_value['name'], 'image_ids': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 次に各カテゴリーに対応するimage_idを追加していく\n",
    "# NOTE: ひとつの画像に足して複数のカテゴリーがある場合がある\n",
    "for ann_dic_val in insta_val_coco.anns.values():\n",
    "    image_id = ann_dic_val['image_id']\n",
    "    category_id = ann_dic_val['category_id']\n",
    "    cat_img_dic[category_id]['image_ids'].append(image_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "減る前の確認. personの数は=  88153\n",
      "減ったか確認. personの数は=  21634\n"
     ]
    }
   ],
   "source": [
    "# image_idsをユニークにする\n",
    "print('減る前の確認. personの数は= ', len(cat_img_dic[1]['image_ids']))\n",
    "for k, v in cat_img_dic.items():\n",
    "    cat_img_dic[k]['image_ids'] = list(set(cat_img_dic[k]['image_ids']))\n",
    "\n",
    "print('減ったか確認. personの数は= ', len(cat_img_dic[1]['image_ids']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# できた！！！ので各カテゴリーにどれぐらいのimageがあるか確認\n",
    "for cat_val in cat_img_dic.values():\n",
    "    print('カテゴリ名 = ', cat_val['name'])\n",
    "    print('imageの数 = ', len(cat_val['image_ids']))\n",
    "    print('--------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "実際に分けていく。valとtrainで分ける。\n",
    "1. cat_img_dicを作成する\n",
    "1. caption.jsonを読み込んで、対応するimageの名前とcaptionに対応した辞書を作る\n",
    "1. annotationをappendする\n",
    "\n",
    "```\n",
    "category_split\n",
    "├── person_en\n",
    "│   ├── train_filenames.pickle\n",
    "│   ├── val_filenames.pickle\n",
    "│   └── text\n",
    "│       └── COCO_VAL_0000.txt\n",
    "└── person_ja\n",
    "    ├── train_filenames.pickle\n",
    "    ├── val_filenames.pickle\n",
    "    └── text\n",
    "        └── COCO_VAL_0000.txt\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "cat_images_dicを作成する関数\n",
    "cat_images_dic = {id: {'name': 'person', 'image_ids: [...]},\n",
    "                  id: {'name': 'person', 'image_ids: [...]},\n",
    "                  ...\n",
    "                  }\n",
    "'''\n",
    "def make_cat_images_dic(insta_path):\n",
    "    insta_coco = COCO(insta_path)\n",
    "\n",
    "\n",
    "    cat_images_dic = dict()\n",
    "    # 最初にカテゴリーのidとname, image_idsの空配列を最初に作る\n",
    "    for cat_value in insta_coco.cats.values():\n",
    "        cat_images_dic[cat_value['id']] = {'name': cat_value['name'], 'image_ids': []}\n",
    "\n",
    "\n",
    "    # 次に各カテゴリーに対応するimage_idを追加していく\n",
    "    # NOTE: ひとつの画像に足して複数のカテゴリーがある場合がある\n",
    "    for ann_dic_val in insta_coco.anns.values():\n",
    "        image_id = ann_dic_val['image_id']\n",
    "        category_id = ann_dic_val['category_id']\n",
    "        cat_images_dic[category_id]['image_ids'].append(image_id)\n",
    "\n",
    "    # image_idsをユニークにする\n",
    "    for k, v in cat_images_dic.items():\n",
    "        cat_images_dic[k]['image_ids'] = list(set(cat_images_dic[k]['image_ids']))\n",
    "    \n",
    "    return cat_images_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "imageとcaptionが対応したdictを作成する関数\n",
    "image_captions_dic = {id: {'name': file_name, 'captions': [...]},\n",
    "                      id: {'name': file_name, 'captions': [...]},\n",
    "                      ...\n",
    "                      }\n",
    "'''\n",
    "\n",
    "def make_image_captions_dic(caption_path):\n",
    "    # json読み込み\n",
    "    with open(caption_path, encoding='utf-8') as f:\n",
    "        json_data = json.load(f)\n",
    "    \n",
    "    image_captions = {}\n",
    "    for i in range(len(json_data[\"images\"])):\n",
    "        file_name = json_data[\"images\"][i][\"file_name\"]\n",
    "        image_id = json_data[\"images\"][i][\"id\"]\n",
    "        image_captions[image_id] = {'name': file_name.replace('.jpg', ''), 'captions': []}\n",
    "    \n",
    "    for annotation in json_data['annotations']:\n",
    "        image_id = annotation['image_id']\n",
    "        if 'tokenized_caption' in annotation:\n",
    "            image_captions[image_id]['captions'].append(annotation['tokenized_caption'])\n",
    "        elif 'caption' in annotation:\n",
    "            image_captions[image_id]['captions'].append(annotation['caption'])\n",
    "    \n",
    "    return image_captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_text_data(image_ids, image_captions_dic, text_dir_path):\n",
    "    for image_id in image_ids:\n",
    "        w_captions = \"\\n\".join(image_captions_dic[image_id]['captions'])\n",
    "        save_text_path = os.path.join(text_dir_path, image_captions_dic[image_id]['name'] + '.txt')\n",
    "        with open(save_text_path, 'w', encoding='utf-8') as f:\n",
    "            f.write(w_captions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_filenames_pickle(image_ids, image_captions_dic, data_dir_path, train_or_val):\n",
    "    filename_list = []\n",
    "    for image_id in image_ids:\n",
    "        filename_list.append(image_captions_dic[image_id]['name'])\n",
    "    \n",
    "    save_filename_path = os.path.join(data_dir_path, train_or_val + '_filenames.pickle')\n",
    "    with open(save_filename_path, 'wb') as f:\n",
    "        pickle.dump(filename_list,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPLIT_DIR_PATH = '/home/nakachi/data/category_split'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=7.36s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "val_insta_path = '/home/nakachi/data/coco2014/annotations/instances_val2014.json'\n",
    "val_en_caption_path = '/home/nakachi/data/coco2014/annotations/captions_val2014.json'\n",
    "val_ja_caption_path = '/data/Users/nakachi/stair/stair_captions_v1.2_val_tokenized.json'\n",
    "\n",
    "val_cat_images_dic = make_cat_images_dic(val_insta_path)\n",
    "val_en_image_captions_dic = make_image_captions_dic(val_en_caption_path)\n",
    "val_ja_image_captions_dic = make_image_captions_dic(val_ja_caption_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cat_images in val_cat_images_dic.values():\n",
    "    # en: オリジナル\n",
    "    EN_DATA_DIR = os.path.join(SPLIT_DIR_PATH, cat_images['name'] + '_en')\n",
    "    EN_TEXT_DIR = os.path.join(EN_DATA_DIR, 'text')\n",
    "    os.makedirs(EN_TEXT_DIR, exist_ok=True)\n",
    "    make_text_data(cat_images['image_ids'], val_en_image_captions_dic, EN_TEXT_DIR)\n",
    "    make_filenames_pickle(cat_images['image_ids'], val_en_image_captions_dic, EN_DATA_DIR, 'val')\n",
    "    \n",
    "    \n",
    "    # ja: stair\n",
    "    JA_DATA_DIR = os.path.join(SPLIT_DIR_PATH, cat_images['name'] + '_ja')\n",
    "    JA_TEXT_DIR = os.path.join(JA_DATA_DIR, 'text')\n",
    "    os.makedirs(JA_TEXT_DIR, exist_ok=True)\n",
    "    make_text_data(cat_images['image_ids'], val_ja_image_captions_dic, JA_TEXT_DIR)\n",
    "    make_filenames_pickle(cat_images['image_ids'], val_ja_image_captions_dic, JA_DATA_DIR, 'val')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=10.85s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "train_insta_path = '/home/nakachi/data/coco2014/annotations/instances_train2014.json'\n",
    "train_en_caption_path = '/home/nakachi/data/coco2014/annotations/captions_train2014.json'\n",
    "train_ja_caption_path = '/data/Users/nakachi/stair/stair_captions_v1.2_train_tokenized.json'\n",
    "\n",
    "train_cat_images_dic = make_cat_images_dic(train_insta_path)\n",
    "train_en_image_captions_dic = make_image_captions_dic(train_en_caption_path)\n",
    "train_ja_image_captions_dic = make_image_captions_dic(train_ja_caption_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cat_images in train_cat_images_dic.values():\n",
    "    # en: オリジナル\n",
    "    EN_DATA_DIR = os.path.join(SPLIT_DIR_PATH, cat_images['name'] + '_en')\n",
    "    EN_TEXT_DIR = os.path.join(EN_DATA_DIR, 'text')\n",
    "    os.makedirs(EN_TEXT_DIR, exist_ok=True)\n",
    "    make_text_data(cat_images['image_ids'], train_en_image_captions_dic, EN_TEXT_DIR)\n",
    "    make_filenames_pickle(cat_images['image_ids'], train_en_image_captions_dic, EN_DATA_DIR, 'train')\n",
    "    \n",
    "    \n",
    "    # ja: stair\n",
    "    JA_DATA_DIR = os.path.join(SPLIT_DIR_PATH, cat_images['name'] + '_ja')\n",
    "    JA_TEXT_DIR = os.path.join(JA_DATA_DIR, 'text')\n",
    "    os.makedirs(JA_TEXT_DIR, exist_ok=True)\n",
    "    make_text_data(cat_images['image_ids'], train_ja_image_captions_dic, JA_TEXT_DIR)\n",
    "    make_filenames_pickle(cat_images['image_ids'], train_ja_image_captions_dic, JA_DATA_DIR, 'train')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "できた！！！\n",
    "次はデータの統計を掴む"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandasに適用するためにそれぞれのlistを作る\n",
    "train_list = []\n",
    "val_list = []\n",
    "\n",
    "for train_value in train_cat_images_dic.values():\n",
    "    append_list = [train_value['name'], len(train_value['image_ids'])]\n",
    "    train_list.append(append_list)\n",
    "    \n",
    "for val_value in val_cat_images_dic.values():\n",
    "    append_list = [val_value['name'], len(val_value['image_ids'])]\n",
    "    val_list.append(append_list)\n",
    "\n",
    "train_df = pd.DataFrame(train_list)\n",
    "val_df = pd.DataFrame(val_list)\n",
    "train_df.columns = ['name', 'number of image']\n",
    "val_df.columns = ['name', 'number of image']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              name  number of image\n",
      "0           person            45174\n",
      "56           chair             8950\n",
      "2              car             8606\n",
      "60    dining table             8378\n",
      "41             cup             6518\n",
      "39          bottle             5968\n",
      "45            bowl             5028\n",
      "26         handbag             4861\n",
      "7            truck             4321\n",
      "24        backpack             3924\n",
      "13           bench             3844\n",
      "73            book             3734\n",
      "67      cell phone             3322\n",
      "71            sink             3291\n",
      "62              tv             3191\n",
      "57           couch             3170\n",
      "74           clock             3159\n",
      "43           knife             3097\n",
      "58    potted plant             3084\n",
      "16             dog             3041\n",
      "32     sports ball             2986\n",
      "9    traffic light             2893\n",
      "15             cat             2818\n",
      "5              bus             2791\n",
      "25        umbrella             2749\n",
      "27             tie             2667\n",
      "59             bed             2539\n",
      "42            fork             2537\n",
      "75            vase             2530\n",
      "36      skateboard             2511\n",
      "44           spoon             2493\n",
      "63          laptop             2475\n",
      "6            train             2464\n",
      "3       motorcycle             2442\n",
      "38   tennis racket             2368\n",
      "37       surfboard             2343\n",
      "61          toilet             2317\n",
      "1          bicycle             2287\n",
      "4         airplane             2243\n",
      "14            bird             2241\n",
      "30            skis             2209\n",
      "53           pizza             2202\n",
      "65          remote             2180\n",
      "8             boat             2098\n",
      "55            cake             2080\n",
      "17           horse             2068\n",
      "69            oven             2003\n",
      "35  baseball glove             1884\n",
      "34    baseball bat             1804\n",
      "23         giraffe             1798\n",
      "40      wine glass             1771\n",
      "72    refrigerator             1671\n",
      "48        sandwich             1645\n",
      "28        suitcase             1631\n",
      "33            kite             1625\n",
      "46          banana             1618\n",
      "20        elephant             1518\n",
      "29         frisbee             1511\n",
      "77      teddy bear             1510\n",
      "66        keyboard             1471\n",
      "19             cow             1389\n",
      "50        broccoli             1340\n",
      "22           zebra             1324\n",
      "64           mouse             1290\n",
      "49          orange             1216\n",
      "11       stop sign             1214\n",
      "10    fire hydrant             1205\n",
      "51          carrot             1186\n",
      "47           apple             1171\n",
      "31       snowboard             1170\n",
      "18           sheep             1105\n",
      "68       microwave             1089\n",
      "54           donut             1062\n",
      "52         hot dog              821\n",
      "79      toothbrush              700\n",
      "76        scissors              673\n",
      "21            bear              668\n",
      "12   parking meter              481\n",
      "70         toaster              151\n",
      "78      hair drier              128\n"
     ]
    }
   ],
   "source": [
    "train_df_s = train_df.sort_values('number of image', ascending=False)\n",
    "print(train_df_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              name  number of image\n",
      "0           person            21634\n",
      "56           chair             4404\n",
      "2              car             4180\n",
      "60    dining table             3960\n",
      "41             cup             3061\n",
      "39          bottle             2912\n",
      "45            bowl             2397\n",
      "26         handbag             2272\n",
      "7            truck             2056\n",
      "13           bench             1961\n",
      "24        backpack             1832\n",
      "73            book             1828\n",
      "74           clock             1704\n",
      "67      cell phone             1695\n",
      "62              tv             1577\n",
      "71            sink             1574\n",
      "58    potted plant             1540\n",
      "16             dog             1521\n",
      "15             cat             1480\n",
      "57           couch             1448\n",
      "32     sports ball             1445\n",
      "9    traffic light             1437\n",
      "43           knife             1410\n",
      "25        umbrella             1393\n",
      "5              bus             1350\n",
      "37       surfboard             1292\n",
      "59             bed             1292\n",
      "27             tie             1288\n",
      "6            train             1281\n",
      "63          laptop             1232\n",
      "3       motorcycle             1219\n",
      "75            vase             1200\n",
      "38   tennis racket             1193\n",
      "44           spoon             1189\n",
      "61          toilet             1185\n",
      "42            fork             1173\n",
      "14            bird             1121\n",
      "53           pizza             1117\n",
      "1          bicycle             1114\n",
      "36      skateboard             1092\n",
      "8             boat             1048\n",
      "65          remote             1041\n",
      "17           horse             1001\n",
      "30            skis              993\n",
      "69            oven              989\n",
      "55            cake              969\n",
      "28        suitcase              876\n",
      "40      wine glass              872\n",
      "23         giraffe              849\n",
      "35  baseball glove              845\n",
      "4         airplane              840\n",
      "48        sandwich              818\n",
      "34    baseball bat              799\n",
      "72    refrigerator              790\n",
      "29         frisbee              757\n",
      "66        keyboard              750\n",
      "46          banana              728\n",
      "33            kite              727\n",
      "77      teddy bear              724\n",
      "20        elephant              714\n",
      "22           zebra              677\n",
      "64           mouse              674\n",
      "50        broccoli              670\n",
      "19             cow              666\n",
      "10    fire hydrant              592\n",
      "11       stop sign              589\n",
      "51          carrot              578\n",
      "49          orange              568\n",
      "31       snowboard              533\n",
      "54           donut              523\n",
      "68       microwave              512\n",
      "47           apple              491\n",
      "18           sheep              489\n",
      "52         hot dog              452\n",
      "79      toothbrush              341\n",
      "21            bear              341\n",
      "76        scissors              302\n",
      "12   parking meter              261\n",
      "70         toaster               74\n",
      "78      hair drier               70\n"
     ]
    }
   ],
   "source": [
    "val_df_s = val_df.sort_values('number of image', ascending=False)\n",
    "print(val_df_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "241035\n",
      "116592\n"
     ]
    }
   ],
   "source": [
    "# 合計ってどうなってるの...\n",
    "print(train_df['number of image'].sum())\n",
    "print(val_df['number of image'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
